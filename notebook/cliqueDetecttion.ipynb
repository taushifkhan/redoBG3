{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7818854-83de-4109-b8f0-46995b818970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx[default] in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (3.3)\n",
      "Collecting networkx[default]\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from networkx[default]) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.11.0,!=1.11.1,>=1.10 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from networkx[default]) (1.14.0)\n",
      "Requirement already satisfied: matplotlib>=3.7 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from networkx[default]) (3.9.1)\n",
      "Requirement already satisfied: pandas>=2.0 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from networkx[default]) (2.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from matplotlib>=3.7->networkx[default]) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from pandas>=2.0->networkx[default]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from pandas>=2.0->networkx[default]) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.7->networkx[default]) (1.16.0)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for ipython-genutils: [Errno 2] No such file or directory: '/pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages/ipython_genutils-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for jupyter-highlight-selected-word: [Errno 2] No such file or directory: '/pod/2/activities/jaxcc/CATch-project/analysis/tkhan/env/scvi/lib/python3.10/site-packages/jupyter_highlight_selected_word-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: networkx\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.3\n",
      "    Uninstalling networkx-3.3:\n",
      "      Successfully uninstalled networkx-3.3\n",
      "Successfully installed networkx-3.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade networkx[default]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adaaf828-2067-470b-8714-d6f705a1908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4180 cliques.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import multiprocessing as mp\n",
    "\n",
    "def find_cliques_in_subgraph(subgraph):\n",
    "    \"\"\"\n",
    "    Find cliques in a subgraph.\n",
    "    \n",
    "    Parameters:\n",
    "    - subgraph: A NetworkX subgraph to find cliques in.\n",
    "    \n",
    "    Returns:\n",
    "    - cliques: A list of cliques found in the subgraph.\n",
    "    \"\"\"\n",
    "    return list(nx.find_cliques(subgraph))\n",
    "\n",
    "def divide_graph_into_subgraphs(graph, num_partitions):\n",
    "    \"\"\"\n",
    "    Divide a graph into smaller subgraphs for parallel processing.\n",
    "    \n",
    "    Parameters:\n",
    "    - graph: A NetworkX graph.\n",
    "    - num_partitions: Number of subgraphs to create.\n",
    "    \n",
    "    Returns:\n",
    "    - subgraphs: List of subgraphs to process.\n",
    "    \"\"\"\n",
    "    # If the graph is connected, divide by connected components\n",
    "    if nx.is_connected(graph):\n",
    "        return [graph.subgraph(c).copy() for c in nx.connected_components(graph)]\n",
    "    else:\n",
    "        # For unconnected graphs, we use node-based partitioning\n",
    "        nodes = list(graph.nodes)\n",
    "        node_batches = [nodes[i::num_partitions] for i in range(num_partitions)]\n",
    "        subgraphs = [graph.subgraph(batch).copy() for batch in node_batches]\n",
    "        return subgraphs\n",
    "\n",
    "def parallel_clique_detection(graph, num_partitions):\n",
    "    \"\"\"\n",
    "    Parallelize the clique detection using multiprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "    - graph: A NetworkX graph.\n",
    "    - num_partitions: Number of partitions (processes) for parallel processing.\n",
    "    \n",
    "    Returns:\n",
    "    - all_cliques: List of all cliques found across all subgraphs.\n",
    "    \"\"\"\n",
    "    # Step 1: Divide the graph into subgraphs\n",
    "    subgraphs = divide_graph_into_subgraphs(graph, num_partitions)\n",
    "\n",
    "    # Step 2: Set up a pool of workers and apply the function to each subgraph\n",
    "    with mp.Pool(processes=num_partitions) as pool:\n",
    "        results = pool.map(find_cliques_in_subgraph, subgraphs)\n",
    "\n",
    "    # Step 3: Combine the results from each process\n",
    "    all_cliques = [clique for sublist in results for clique in sublist]\n",
    "    \n",
    "    return all_cliques\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create or load your graph\n",
    "    G = nx.barabasi_albert_graph(1000, 5)  # Example graph (use your large graph here)\n",
    "    \n",
    "    # Number of processes to use for parallelization\n",
    "    num_partitions = mp.cpu_count()  # Use all available CPU cores\n",
    "    \n",
    "    # Run parallel clique detection\n",
    "    cliques = parallel_clique_detection(G, num_partitions)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f\"Found {len(cliques)} cliques.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fd34ab-04d0-4841-8458-3b69545cd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = mp.cpu_count()  # Use all available CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2c847a-1bd7-4ec5-acba-a1280d0a01f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ade45-f7f3-4288-b916-e507eec51b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
